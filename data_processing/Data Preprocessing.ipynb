{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "macro-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "import traces\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-peripheral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "formed-providence",
   "metadata": {},
   "source": [
    "# REDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "electoral-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/redd/low_freq/\"\n",
    "applicance_list = [\"mains\", \"dishwaser\", \"refrigerator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "photographic-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labels & create the label map\n",
    "def read_label(base_path):\n",
    "    label = {}\n",
    "    for h_idx in range(1, 7):\n",
    "        h_path = os.path.join(base_path, \"house_{}/labels.dat\".format(h_idx))\n",
    "        label[h_idx] = {}\n",
    "        with open(h_path) as f:\n",
    "            for line in f:\n",
    "                splitted_line = line.split(' ')\n",
    "                label[h_idx][int(splitted_line[0])] = splitted_line[1].strip() + '_' + splitted_line[0]\n",
    "    return label\n",
    "\n",
    "\n",
    "# Read the data\n",
    "def read_data(base_path, h_idx, labels, applicance_list):\n",
    "    h_path = os.path.join(base_path, \"house_{}/\".format(h_idx))\n",
    "    num_apps = len(glob.glob(h_path + 'channel*'))\n",
    "    df = None\n",
    "    for ch_i in range(1, num_apps + 1):\n",
    "        file = h_path + 'channel_{}.dat'.format(ch_i)\n",
    "        if labels[h_idx][ch_i].split(\"_\")[0] in applicance_list:\n",
    "            if df is None:\n",
    "                df = pd.read_table(file, sep = ' ', names = ['unix_time', labels[h_idx][ch_i]], \n",
    "                                                  dtype = {'unix_time': 'int64', labels[h_idx][ch_i]: 'float64'})\n",
    "            else:\n",
    "                data = pd.read_table(file, sep = ' ', names = ['unix_time', labels[h_idx][ch_i]], \n",
    "                                                  dtype = {'unix_time': 'int64', labels[h_idx][ch_i]: 'float64'})\n",
    "                df = pd.merge(df, data, how = 'inner', on = 'unix_time')\n",
    "    df['timestamp'] = df['unix_time'].astype(\"datetime64[s]\")\n",
    "    df = df.set_index(df['timestamp'].values)\n",
    "    df.drop(['unix_time','timestamp'], axis=1, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "associate-canyon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.17 s, sys: 1.68 s, total: 6.86 s\n",
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels = read_label(base_path)\n",
    "df = {}\n",
    "for i in range(1, 7):\n",
    "    df[i] = read_data(base_path, i, labels, applicance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "proved-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mains_1</th>\n",
       "      <th>mains_2</th>\n",
       "      <th>refrigerator_5</th>\n",
       "      <th>dishwaser_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:13</th>\n",
       "      <td>222.20</td>\n",
       "      <td>118.83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:16</th>\n",
       "      <td>223.17</td>\n",
       "      <td>119.19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:20</th>\n",
       "      <td>223.60</td>\n",
       "      <td>118.92</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:23</th>\n",
       "      <td>222.91</td>\n",
       "      <td>119.16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:26</th>\n",
       "      <td>222.94</td>\n",
       "      <td>118.83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mains_1  mains_2  refrigerator_5  dishwaser_6\n",
       "2011-04-18 13:22:13   222.20   118.83             6.0          0.0\n",
       "2011-04-18 13:22:16   223.17   119.19             6.0          0.0\n",
       "2011-04-18 13:22:20   223.60   118.92             6.0          0.0\n",
       "2011-04-18 13:22:23   222.91   119.16             6.0          1.0\n",
       "2011-04-18 13:22:26   222.94   118.83             6.0          0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-cleanup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "direct-reviewer",
   "metadata": {},
   "source": [
    "## Number of houses having a particular appliance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "excited-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_cnt = {}\n",
    "for k, v in labels.items():\n",
    "    cur_app_list = set()\n",
    "    for kk, vv in v.items():\n",
    "        app = \"_\".join(vv.split(\"_\")[:-1])\n",
    "        cur_app_list.add(app)\n",
    "    for cur_app in cur_app_list:\n",
    "        if app_cnt.get(cur_app) is None:\n",
    "            app_cnt[cur_app] = 0\n",
    "        app_cnt[cur_app] += 1\n",
    "        \n",
    "app_cnt = dict(sorted(app_cnt.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "assumed-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'washer_dryer': 6, 'mains': 6, 'kitchen_outlets': 6, 'dishwaser': 6, 'lighting': 6, 'refrigerator': 5, 'bathroom_gfi': 5, 'microwave': 4, 'stove': 4, 'outlets_unknown': 4, 'electric_heat': 3, 'disposal': 3, 'electronics': 3, 'furance': 3, 'smoke_alarms': 2, 'air_conditioning': 2, 'oven': 1, 'miscellaeneous': 1, 'outdoor_outlets': 1, 'subpanel': 1}\n"
     ]
    }
   ],
   "source": [
    "print(app_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-injury",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "productive-yellow",
   "metadata": {},
   "source": [
    "## Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-release",
   "metadata": {},
   "source": [
    "### 1. Add Zero Boundary Records when data is not available for more than 180 seconds (3min):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pursuant-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is no data for more than 180 seconds (3min), fill zeros\n",
    "second_threshold = 180\n",
    "boundary_second_interval = 5\n",
    "num_input_vals = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "thirty-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createZeroRecordsDF(cur_timestamp_list, col_list, cur_input_vals=4, cur_boundary_second_interval=5):\n",
    "    zero_end_records = []\n",
    "    for cur_ts in cur_timestamp_list:\n",
    "        cur_ts_new = cur_ts + timedelta(seconds=cur_boundary_second_interval)\n",
    "        cur_record = [cur_ts_new] + [0] * cur_input_vals\n",
    "        zero_end_records.append(cur_record)\n",
    "\n",
    "    zero_end_records_df = pd.DataFrame(zero_end_records, columns=col_list)\n",
    "    zero_end_records_df = zero_end_records_df.set_index(zero_end_records_df['time_stamp'].values)\n",
    "    return zero_end_records_df\n",
    "\n",
    "def addZeroBoundaryRecords(cur_df):\n",
    "    col_list = [\"time_stamp\"] + list(cur_df.columns)\n",
    "    cur_df[\"time_stamp\"] = cur_df.index\n",
    "    \n",
    "    cur_df[\"time_diff\"] = cur_df[\"time_stamp\"].diff(periods = 1).dt.total_seconds()\n",
    "    cur_df[\"prev_time_diff\"] = cur_df[\"time_diff\"].shift(periods = -1)\n",
    "    \n",
    "    cur_input_vals = len(col_list) - 1\n",
    "    prev_timestamps = list(cur_df[cur_df[\"prev_time_diff\"] >= second_threshold][\"time_stamp\"])\n",
    "    next_zero_boundary_records = createZeroRecordsDF(prev_timestamps, col_list, cur_input_vals, boundary_second_interval)\n",
    "    cur_df = cur_df.append(next_zero_boundary_records)\n",
    "    \n",
    "    next_timestamps = list(cur_df[cur_df[\"time_diff\"] >= second_threshold][\"time_stamp\"])\n",
    "    prev_zero_boundary_ecords = createZeroRecordsDF(next_timestamps, col_list, cur_input_vals, -1 * boundary_second_interval)\n",
    "    cur_df = cur_df.append(prev_zero_boundary_ecords)\n",
    "    \n",
    "    # Sort by Timestamp\n",
    "    cur_df.sort_index(inplace=True)\n",
    "    cur_df.drop(columns=[\"time_stamp\", \"time_diff\", \"prev_time_diff\"], inplace=True)\n",
    "    \n",
    "    return cur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bronze-invalid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 406 ms, sys: 154 ms, total: 559 ms\n",
      "Wall time: 559 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1, 7):\n",
    "    df[i] = addZeroBoundaryRecords(df[i].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "literary-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dishwaser_6</th>\n",
       "      <th>mains_1</th>\n",
       "      <th>mains_2</th>\n",
       "      <th>refrigerator_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>222.20</td>\n",
       "      <td>118.83</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>223.17</td>\n",
       "      <td>119.19</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>223.60</td>\n",
       "      <td>118.92</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>222.91</td>\n",
       "      <td>119.16</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>222.94</td>\n",
       "      <td>118.83</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dishwaser_6  mains_1  mains_2  refrigerator_5\n",
       "2011-04-18 13:22:13          0.0   222.20   118.83             6.0\n",
       "2011-04-18 13:22:16          0.0   223.17   119.19             6.0\n",
       "2011-04-18 13:22:20          0.0   223.60   118.92             6.0\n",
       "2011-04-18 13:22:23          1.0   222.91   119.16             6.0\n",
       "2011-04-18 13:22:26          0.0   222.94   118.83             6.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-tradition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "another-secretary",
   "metadata": {},
   "source": [
    "### 2. Check the sampling rate and resample everything to 3 second interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "advisory-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate_seconds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "processed-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleDF(cur_df, cur_sampling_rate):\n",
    "    col_list = list(cur_df.columns)\n",
    "    cur_df[\"time_stamp\"] = cur_df.index\n",
    "    out_df = pd.DataFrame(columns=cur_df.columns)\n",
    "    for cur_col in col_list:\n",
    "        cur_val_list = cur_df[[\"time_stamp\", cur_col]].values.tolist()\n",
    "        \n",
    "        start_time = cur_val_list[0][0]\n",
    "        end_time = cur_val_list[-1][0]\n",
    "        \n",
    "        # Create the traces TimeSeries Object and resample\n",
    "        cur_ts = traces.TimeSeries(cur_val_list)\n",
    "        cur_ts_sampled = cur_ts.sample(\n",
    "            sampling_period=timedelta(seconds=cur_sampling_rate),\n",
    "            start=start_time,\n",
    "            end=end_time,\n",
    "            interpolate='linear',\n",
    "        )\n",
    "        out_df[\"time_stamp\"] = [x[0] for x in cur_ts_sampled]\n",
    "        out_df[cur_col] = [round(x[1],3) for x in cur_ts_sampled]\n",
    "        \n",
    "        print(\"Finished interpolating the column =\", cur_col)\n",
    "        \n",
    "        # Free up memory\n",
    "        del cur_ts\n",
    "        \n",
    "    out_df.set_index(\"time_stamp\", inplace=True)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "frank-florida",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House 1:\n",
      "Finished interpolating the column = dishwaser_6\n",
      "Finished interpolating the column = mains_1\n",
      "Finished interpolating the column = mains_2\n",
      "Finished interpolating the column = refrigerator_5\n",
      "\n",
      "\n",
      "House 2:\n",
      "Finished interpolating the column = dishwaser_10\n",
      "Finished interpolating the column = mains_1\n",
      "Finished interpolating the column = mains_2\n",
      "Finished interpolating the column = refrigerator_9\n",
      "\n",
      "\n",
      "House 3:\n",
      "Finished interpolating the column = dishwaser_9\n",
      "Finished interpolating the column = mains_1\n",
      "Finished interpolating the column = mains_2\n",
      "Finished interpolating the column = refrigerator_7\n",
      "\n",
      "\n",
      "House 4:\n",
      "Finished interpolating the column = dishwaser_15\n",
      "Finished interpolating the column = mains_1\n",
      "Finished interpolating the column = mains_2\n",
      "\n",
      "\n",
      "House 5:\n",
      "Finished interpolating the column = dishwaser_20\n",
      "Finished interpolating the column = mains_1\n",
      "Finished interpolating the column = mains_2\n",
      "Finished interpolating the column = refrigerator_18\n",
      "\n",
      "\n",
      "House 6:\n",
      "Finished interpolating the column = dishwaser_9\n",
      "Finished interpolating the column = mains_1\n",
      "Finished interpolating the column = mains_2\n",
      "Finished interpolating the column = refrigerator_8\n",
      "\n",
      "\n",
      "CPU times: user 17min 4s, sys: 5.85 s, total: 17min 9s\n",
      "Wall time: 17min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_resampled = {}\n",
    "for i in range(1, 7):\n",
    "    print(\"House \" + str(i) + \":\")\n",
    "    df_resampled[i] = resampleDF(df[i].copy(), sampling_rate_seconds)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "continental-camel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dishwaser_6</th>\n",
       "      <th>mains_1</th>\n",
       "      <th>mains_2</th>\n",
       "      <th>refrigerator_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_stamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:13</th>\n",
       "      <td>0.000</td>\n",
       "      <td>222.200</td>\n",
       "      <td>118.830</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:16</th>\n",
       "      <td>0.000</td>\n",
       "      <td>223.170</td>\n",
       "      <td>119.190</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:19</th>\n",
       "      <td>0.000</td>\n",
       "      <td>223.493</td>\n",
       "      <td>118.987</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:22</th>\n",
       "      <td>0.667</td>\n",
       "      <td>223.140</td>\n",
       "      <td>119.080</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:25</th>\n",
       "      <td>0.333</td>\n",
       "      <td>222.930</td>\n",
       "      <td>118.940</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dishwaser_6  mains_1  mains_2  refrigerator_5\n",
       "time_stamp                                                        \n",
       "2011-04-18 13:22:13        0.000  222.200  118.830             6.0\n",
       "2011-04-18 13:22:16        0.000  223.170  119.190             6.0\n",
       "2011-04-18 13:22:19        0.000  223.493  118.987             6.0\n",
       "2011-04-18 13:22:22        0.667  223.140  119.080             6.0\n",
       "2011-04-18 13:22:25        0.333  222.930  118.940             6.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-reporter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "measured-cream",
   "metadata": {},
   "source": [
    "### 3. Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "emotional-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDF(cur_df, input_cols = [\"mains_1\", \"mains_2\"], return_params=True):\n",
    "    cur_df_mean = cur_df[input_cols].mean(axis=0)\n",
    "    cur_df_std = cur_df[input_cols].std(axis=0)\n",
    "    out_df = cur_df\n",
    "    out_df[input_cols] = (out_df[input_cols] - cur_df_mean)/(cur_df_std)\n",
    "    \n",
    "    params = {}\n",
    "    params[\"mean_vector\"] = cur_df_mean.to_json()\n",
    "    params[\"std_vector\"] = cur_df_std.to_json()\n",
    "    \n",
    "    if return_params:\n",
    "        return out_df, params\n",
    "    else:\n",
    "        return out_df\n",
    "    \n",
    "def renormalizeDF(cur_df, input_cols = [\"mains_1\", \"mains_2\"], params=None):\n",
    "    out_df = cur_df\n",
    "    out_df[input_cols] = (out_df[input_cols] * pd.read_json(params[\"std_vector\"], typ='series')) + pd.read_json(params[\"mean_vector\"], typ='series')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "increasing-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 577 ms, sys: 227 ms, total: 804 ms\n",
      "Wall time: 650 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalization_params = {}\n",
    "df_normalized = {}\n",
    "for i in range(1, 7):\n",
    "    df_normalized[i], normalization_params[i] = normalizeDF(df_resampled[i].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "specific-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dishwaser_6</th>\n",
       "      <th>mains_1</th>\n",
       "      <th>mains_2</th>\n",
       "      <th>refrigerator_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_stamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:13</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.347528</td>\n",
       "      <td>0.128814</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:16</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350646</td>\n",
       "      <td>0.129969</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:19</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.351684</td>\n",
       "      <td>0.129318</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:22</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.350550</td>\n",
       "      <td>0.129616</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:25</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.349875</td>\n",
       "      <td>0.129167</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dishwaser_6   mains_1   mains_2  refrigerator_5\n",
       "time_stamp                                                          \n",
       "2011-04-18 13:22:13        0.000  0.347528  0.128814             6.0\n",
       "2011-04-18 13:22:16        0.000  0.350646  0.129969             6.0\n",
       "2011-04-18 13:22:19        0.000  0.351684  0.129318             6.0\n",
       "2011-04-18 13:22:22        0.667  0.350550  0.129616             6.0\n",
       "2011-04-18 13:22:25        0.333  0.349875  0.129167             6.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "environmental-aluminum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_vector': '{\"mains_1\":114.0950544201,\"mains_2\":78.6753711835}',\n",
       " 'std_vector': '{\"mains_1\":311.06848957,\"mains_2\":311.7258815882}'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-convert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fresh-cleaner",
   "metadata": {},
   "source": [
    "### 4. Store the normalized data and normalization params: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "federal-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the normalization params and the normalized output:\n",
    "out_base_dir = \"../data/redd_processed/low_freq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "incoming-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(out_base_dir):\n",
    "    os.makedirs(out_base_dir)\n",
    "\n",
    "for i in range(1, 7):\n",
    "    cur_house_data_path = os.path.join(out_base_dir, \"house_{}_data.csv\".format(i))\n",
    "    cur_house_params_path = os.path.join(out_base_dir, \"house_{}_norm_params.json\".format(i))\n",
    "    \n",
    "    # Store the house data\n",
    "    df_normalized[i].to_csv(cur_house_data_path)\n",
    "    \n",
    "    # Store the house normalization params (useful to renormalize the data if needed after prediction)\n",
    "    with open(cur_house_params_path, \"w\") as f:\n",
    "        json.dump(normalization_params[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-jacket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "protecting-calculation",
   "metadata": {},
   "source": [
    "## Train/test split:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-cruise",
   "metadata": {},
   "source": [
    "### 1. Create windows of data points with a given window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "maritime-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSamples(cur_df, cur_window_segment=33, target_col=\"dishwaser\", causal=False):\n",
    "    cur_df_cols = list(cur_df.columns)\n",
    "    cur_df_timestamps = cur_df[\"time_stamp\"]\n",
    "    cur_df = cur_df.round(4)\n",
    "    cur_df_list = cur_df.to_numpy()\n",
    "    input_cols=[\"mains_1\", \"mains_2\"]\n",
    "    \n",
    "    # Find the col idx\n",
    "    input_col_idx = []\n",
    "    target_col_idx = None\n",
    "    for idx, cur_col in enumerate(cur_df_cols):\n",
    "        if target_col in cur_col:\n",
    "            target_col_idx = idx\n",
    "            break\n",
    "     \n",
    "    for inp_col in input_cols:\n",
    "        input_col_idx.append(cur_df_cols.index(inp_col))\n",
    "            \n",
    "    # Create the data samples\n",
    "    x_cols = [\"time_stamp\"]\n",
    "    for inp_col in input_cols:\n",
    "        prev_list = []\n",
    "        for i in range(cur_window_segment-1):\n",
    "            prev_list.append(inp_col + \"_prev_\" + str(i+1))\n",
    "        prev_list = list(reversed(prev_list))\n",
    "\n",
    "        next_list = []\n",
    "        if not causal:\n",
    "            for i in range(cur_window_segment-1):\n",
    "                next_list.append(inp_col + \"_next_\" + str(i+1))\n",
    "            \n",
    "        x_cols += prev_list + [inp_col] + next_list\n",
    "    \n",
    "    y_cols = [\"output\"]\n",
    "    cols = x_cols + y_cols\n",
    "    data = []\n",
    "        \n",
    "    num_records = len(cur_df_list)\n",
    "    for idx in range(num_records):\n",
    "        cur_start = idx - cur_window_segment + 1\n",
    "        \n",
    "        if causal:\n",
    "            cur_end = idx + 1\n",
    "        else:\n",
    "            cur_end = idx + cur_window_segment\n",
    "        \n",
    "        if cur_start < 0 or cur_end > num_records:\n",
    "            continue\n",
    "            \n",
    "        cur_timestamp = [cur_df_timestamps[idx]]\n",
    "        cur_input = None\n",
    "        for inp_col_idx in input_col_idx:\n",
    "            if cur_input is None:\n",
    "                cur_input = list(cur_df_list[cur_start:cur_end, inp_col_idx])\n",
    "            else:\n",
    "                cur_input += list(cur_df_list[cur_start:cur_end, inp_col_idx])\n",
    "        \n",
    "        # Filter the samples containing all same values for mains_1 window and mains_2 window (so only 2 unique values):\n",
    "        if len(np.unique(cur_input)) <= 2:\n",
    "            continue\n",
    "        \n",
    "        cur_output = list(cur_df_list[idx, [target_col_idx]])\n",
    "        data.append(cur_timestamp + cur_input + cur_output)\n",
    "\n",
    "    df_out = pd.DataFrame(data=data, columns=cols)\n",
    "    return df_out\n",
    "\n",
    "def create_train_test_split(data_dir, out_dir, window_segment = 3, train_house_list = [1, 2, 3, 4], test_house_list = [5, 6]):\n",
    "    # Note: Window segment should be of the form 2^n + 1\n",
    "    appliance_list = [\"refrigerator\", \"dishwaser\"]\n",
    "    causal_type = False\n",
    "    \n",
    "    for cur_appliance in appliance_list:\n",
    "        # Create training data\n",
    "        df_train = None\n",
    "        \n",
    "        print(\"Appliance =\", cur_appliance)\n",
    "        for cur_house_idx in tqdm(train_house_list):\n",
    "            \n",
    "            try:\n",
    "                house_data_path = os.path.join(data_dir, \"house_{}_data.csv\".format(cur_house_idx))\n",
    "                cur_df = pd.read_csv(house_data_path)\n",
    "\n",
    "                if df_train is None:\n",
    "                    df_train = createSamples(cur_df.copy(), cur_window_segment=window_segment, target_col=cur_appliance, causal=causal_type)\n",
    "                    df_train[\"house_idx\"] = cur_house_idx\n",
    "                else:\n",
    "                    c_df = createSamples(cur_df.copy(), cur_window_segment=window_segment, target_col=cur_appliance, causal=causal_type)\n",
    "                    c_df[\"house_idx\"] = cur_house_idx\n",
    "                    df_train = df_train.append(c_df, ignore_index=True)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(\"Skipped House =\", cur_house_idx, \" for appliance =\", cur_appliance)\n",
    "                \n",
    "        # Write the output to folder\n",
    "        out_app_folder = os.path.join(out_dir, \"window_{}\".format(window_segment), cur_appliance)\n",
    "        \n",
    "        if not os.path.exists(out_app_folder):\n",
    "            os.makedirs(out_app_folder)\n",
    "        \n",
    "        out_train_path = os.path.join(out_app_folder, \"train.csv\")\n",
    "        print(\"Writing data to \", out_train_path)\n",
    "        df_train.set_index(\"time_stamp\", inplace=True)\n",
    "        df_train.to_csv(out_train_path)\n",
    "        \n",
    "        \n",
    "        # Create testing data\n",
    "        df_test = None\n",
    "        for cur_house_idx in tqdm(test_house_list):\n",
    "            \n",
    "            try:\n",
    "                house_data_path = os.path.join(data_dir, \"house_{}_data.csv\".format(cur_house_idx))\n",
    "                cur_df = pd.read_csv(house_data_path)\n",
    "\n",
    "                if df_test is None:\n",
    "                    df_test = createSamples(cur_df.copy(), cur_window_segment=window_segment, target_col=cur_appliance, causal=causal_type)\n",
    "                    df_test[\"house_idx\"] = cur_house_idx\n",
    "                else:\n",
    "                    c_df = createSamples(cur_df.copy(), cur_window_segment=window_segment, target_col=cur_appliance, causal=causal_type)\n",
    "                    c_df[\"house_idx\"] = cur_house_idx\n",
    "                    df_test = df_test.append(c_df, ignore_index=True)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(\"Skipped House =\", cur_house_idx, \" for appliance =\", cur_appliance)\n",
    "        \n",
    "        # Write the output to folder\n",
    "        out_test_path = os.path.join(out_app_folder, \"test.csv\")\n",
    "        print(\"Writing data to \", out_test_path)\n",
    "        df_test.set_index(\"time_stamp\", inplace=True)\n",
    "        df_test.to_csv(out_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "instrumental-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dir = \"../data/redd_processed/low_freq/\"\n",
    "out_dir = \"../data/redd_processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "create_train_test_split(inp_dir, out_dir, window_segment = 3, train_house_list = [1], test_house_list = [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-verification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-solid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "window_seg_list = [33, 65, 129, 257]\n",
    "for cur_seg in window_seg_list:\n",
    "    create_train_test_split(inp_dir, out_dir, window_segment = cur_seg, train_house_list = [1, 2, 3, 4], test_house_list = [5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-carry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-ending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-medicaid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
