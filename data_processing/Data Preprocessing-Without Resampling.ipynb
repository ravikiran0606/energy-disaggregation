{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "macro-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "import traces\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-peripheral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "formed-providence",
   "metadata": {},
   "source": [
    "# REDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electoral-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/redd/low_freq/\"\n",
    "applicance_list = [\"mains\", \"dishwaser\", \"refrigerator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "photographic-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labels & create the label map\n",
    "def read_label(base_path):\n",
    "    label = {}\n",
    "    for h_idx in range(1, 7):\n",
    "        h_path = os.path.join(base_path, \"house_{}/labels.dat\".format(h_idx))\n",
    "        label[h_idx] = {}\n",
    "        with open(h_path) as f:\n",
    "            for line in f:\n",
    "                splitted_line = line.split(' ')\n",
    "                label[h_idx][int(splitted_line[0])] = splitted_line[1].strip() + '_' + splitted_line[0]\n",
    "    return label\n",
    "\n",
    "\n",
    "# Read the data\n",
    "def read_data(base_path, h_idx, labels, applicance_list):\n",
    "    h_path = os.path.join(base_path, \"house_{}/\".format(h_idx))\n",
    "    num_apps = len(glob.glob(h_path + 'channel*'))\n",
    "    df = None\n",
    "    for ch_i in range(1, num_apps + 1):\n",
    "        file = h_path + 'channel_{}.dat'.format(ch_i)\n",
    "        if labels[h_idx][ch_i].split(\"_\")[0] in applicance_list:\n",
    "            if df is None:\n",
    "                df = pd.read_table(file, sep = ' ', names = ['unix_time', labels[h_idx][ch_i]], \n",
    "                                                  dtype = {'unix_time': 'int64', labels[h_idx][ch_i]: 'float64'})\n",
    "            else:\n",
    "                data = pd.read_table(file, sep = ' ', names = ['unix_time', labels[h_idx][ch_i]], \n",
    "                                                  dtype = {'unix_time': 'int64', labels[h_idx][ch_i]: 'float64'})\n",
    "                df = pd.merge(df, data, how = 'inner', on = 'unix_time')\n",
    "    df['timestamp'] = df['unix_time'].astype(\"datetime64[s]\")\n",
    "    df = df.set_index(df['timestamp'].values)\n",
    "    df.drop(['unix_time','timestamp'], axis=1, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "associate-canyon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.18 s, sys: 1.73 s, total: 6.91 s\n",
      "Wall time: 6.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels = read_label(base_path)\n",
    "df = {}\n",
    "for i in range(1, 7):\n",
    "    df[i] = read_data(base_path, i, labels, applicance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proved-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mains_1</th>\n",
       "      <th>mains_2</th>\n",
       "      <th>refrigerator_5</th>\n",
       "      <th>dishwaser_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:13</th>\n",
       "      <td>222.20</td>\n",
       "      <td>118.83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:16</th>\n",
       "      <td>223.17</td>\n",
       "      <td>119.19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:20</th>\n",
       "      <td>223.60</td>\n",
       "      <td>118.92</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:23</th>\n",
       "      <td>222.91</td>\n",
       "      <td>119.16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:26</th>\n",
       "      <td>222.94</td>\n",
       "      <td>118.83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mains_1  mains_2  refrigerator_5  dishwaser_6\n",
       "2011-04-18 13:22:13   222.20   118.83             6.0          0.0\n",
       "2011-04-18 13:22:16   223.17   119.19             6.0          0.0\n",
       "2011-04-18 13:22:20   223.60   118.92             6.0          0.0\n",
       "2011-04-18 13:22:23   222.91   119.16             6.0          1.0\n",
       "2011-04-18 13:22:26   222.94   118.83             6.0          0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-cleanup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "direct-reviewer",
   "metadata": {},
   "source": [
    "## Number of houses having a particular appliance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excited-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_cnt = {}\n",
    "for k, v in labels.items():\n",
    "    cur_app_list = set()\n",
    "    for kk, vv in v.items():\n",
    "        app = \"_\".join(vv.split(\"_\")[:-1])\n",
    "        cur_app_list.add(app)\n",
    "    for cur_app in cur_app_list:\n",
    "        if app_cnt.get(cur_app) is None:\n",
    "            app_cnt[cur_app] = 0\n",
    "        app_cnt[cur_app] += 1\n",
    "        \n",
    "app_cnt = dict(sorted(app_cnt.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assumed-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mains': 6, 'washer_dryer': 6, 'dishwaser': 6, 'lighting': 6, 'kitchen_outlets': 6, 'bathroom_gfi': 5, 'refrigerator': 5, 'microwave': 4, 'stove': 4, 'outlets_unknown': 4, 'electric_heat': 3, 'disposal': 3, 'electronics': 3, 'furance': 3, 'smoke_alarms': 2, 'air_conditioning': 2, 'oven': 1, 'miscellaeneous': 1, 'subpanel': 1, 'outdoor_outlets': 1}\n"
     ]
    }
   ],
   "source": [
    "print(app_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-injury",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "productive-yellow",
   "metadata": {},
   "source": [
    "## Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-cream",
   "metadata": {},
   "source": [
    "### 1. Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "emotional-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDF(cur_df, input_cols = [\"mains_1\", \"mains_2\"], return_params=True):\n",
    "    cur_df_mean = cur_df[input_cols].mean(axis=0)\n",
    "    cur_df_std = cur_df[input_cols].std(axis=0)\n",
    "    out_df = cur_df\n",
    "    out_df[input_cols] = (out_df[input_cols] - cur_df_mean)/(cur_df_std)\n",
    "    \n",
    "    params = {}\n",
    "    params[\"mean_vector\"] = cur_df_mean.to_json()\n",
    "    params[\"std_vector\"] = cur_df_std.to_json()\n",
    "    \n",
    "    if return_params:\n",
    "        return out_df, params\n",
    "    else:\n",
    "        return out_df\n",
    "    \n",
    "def renormalizeDF(cur_df, input_cols = [\"mains_1\", \"mains_2\"], params=None):\n",
    "    out_df = cur_df\n",
    "    out_df[input_cols] = (out_df[input_cols] * pd.read_json(params[\"std_vector\"], typ='series')) + pd.read_json(params[\"mean_vector\"], typ='series')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "increasing-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 45.9 ms, total: 166 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalization_params = {}\n",
    "df_normalized = {}\n",
    "for i in range(1, 7):\n",
    "    df_normalized[i], normalization_params[i] = normalizeDF(df[i].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "specific-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mains_1</th>\n",
       "      <th>mains_2</th>\n",
       "      <th>refrigerator_5</th>\n",
       "      <th>dishwaser_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:13</th>\n",
       "      <td>-0.012578</td>\n",
       "      <td>-0.087639</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:16</th>\n",
       "      <td>-0.010210</td>\n",
       "      <td>-0.086793</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:20</th>\n",
       "      <td>-0.009161</td>\n",
       "      <td>-0.087427</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:23</th>\n",
       "      <td>-0.010845</td>\n",
       "      <td>-0.086864</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18 13:22:26</th>\n",
       "      <td>-0.010772</td>\n",
       "      <td>-0.087639</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mains_1   mains_2  refrigerator_5  dishwaser_6\n",
       "2011-04-18 13:22:13 -0.012578 -0.087639             6.0          0.0\n",
       "2011-04-18 13:22:16 -0.010210 -0.086793             6.0          0.0\n",
       "2011-04-18 13:22:20 -0.009161 -0.087427             6.0          0.0\n",
       "2011-04-18 13:22:23 -0.010845 -0.086864             6.0          1.0\n",
       "2011-04-18 13:22:26 -0.010772 -0.087639             6.0          0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "environmental-aluminum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_vector': '{\"mains_1\":227.3531298494,\"mains_2\":156.1432875884}',\n",
       " 'std_vector': '{\"mains_1\":409.6954279752,\"mains_2\":425.762416359}'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "preceding-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_base_dir = \"../data/redd_processed/\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(out_base_dir):\n",
    "    os.makedirs(out_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "modular-stocks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mains_1</th>\n",
       "      <th>mains_2</th>\n",
       "      <th>refrigerator_5</th>\n",
       "      <th>dishwaser_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.067480e+05</td>\n",
       "      <td>4.067480e+05</td>\n",
       "      <td>406748.000000</td>\n",
       "      <td>406748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.658697e-15</td>\n",
       "      <td>-5.510896e-15</td>\n",
       "      <td>55.504096</td>\n",
       "      <td>24.917698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>89.149730</td>\n",
       "      <td>149.718191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.283258e-01</td>\n",
       "      <td>-2.804928e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.300821e-01</td>\n",
       "      <td>-2.753491e-01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.366957e-01</td>\n",
       "      <td>-2.688666e-01</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.734672e-02</td>\n",
       "      <td>-8.801455e-02</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.428868e+01</td>\n",
       "      <td>1.440305e+01</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mains_1       mains_2  refrigerator_5    dishwaser_6\n",
       "count  4.067480e+05  4.067480e+05   406748.000000  406748.000000\n",
       "mean  -4.658697e-15 -5.510896e-15       55.504096      24.917698\n",
       "std    1.000000e+00  1.000000e+00       89.149730     149.718191\n",
       "min   -4.283258e-01 -2.804928e-01        0.000000       0.000000\n",
       "25%   -3.300821e-01 -2.753491e-01        6.000000       0.000000\n",
       "50%   -2.366957e-01 -2.688666e-01        7.000000       0.000000\n",
       "75%    1.734672e-02 -8.801455e-02      181.000000       0.000000\n",
       "max    1.428868e+01  1.440305e+01     2359.000000    1422.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized[1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-jersey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-classification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-drunk",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "divine-partnership",
   "metadata": {},
   "source": [
    "### 2. Split into continuous segments and store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "north-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSegments_Store(cur_df, cur_path=\"\", appliance=\"refrigerator\", split_second_threshold=10800):\n",
    "    target_col = None\n",
    "    for cur_col in cur_df.columns:\n",
    "        if appliance in cur_col:\n",
    "            target_col = cur_col\n",
    "            break\n",
    "            \n",
    "    if target_col is None:\n",
    "        print(\"Column doesn't exist!\")\n",
    "        return\n",
    "    \n",
    "    cur_df.rename(columns={target_col:\"output\"}, inplace=True)\n",
    "    cur_df[\"time_stamp\"] = cur_df.index\n",
    "    cur_df[\"time_diff\"] = cur_df[\"time_stamp\"].diff(periods = 1).dt.total_seconds()\n",
    "    split_timestamps = [cur_df.iloc[0][\"time_stamp\"]]\n",
    "    split_timestamps += list(cur_df[cur_df[\"time_diff\"] > split_second_threshold][\"time_stamp\"])\n",
    "    split_timestamps += [cur_df.iloc[-1][\"time_stamp\"]]\n",
    "    \n",
    "    num_segments = len(split_timestamps) - 1\n",
    "   \n",
    "    cols = [\"mains_1\", \"mains_2\", \"output\"]\n",
    "    for i in range(len(split_timestamps)-1):\n",
    "        start_timestamp = split_timestamps[i]\n",
    "        end_timestamp = split_timestamps[i+1]\n",
    "        \n",
    "        cur_seg_df = cur_df[(cur_df[\"time_stamp\"] >= start_timestamp) & (cur_df[\"time_stamp\"] < end_timestamp)].copy()\n",
    "        cur_seg_df = cur_seg_df[cols]\n",
    "        cur_seg_path = cur_path.format(i+1)\n",
    "        print(\"Writing to \", cur_seg_path)\n",
    "        cur_seg_df.to_csv(cur_seg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store the normalized data:\n",
    "\n",
    "# train_house_list = [1, 2, 3, 4]\n",
    "# test_house_list = [5, 6]\n",
    "# appliance_list = [\"refrigerator\", \"dishwaser\"]\n",
    "\n",
    "# out_base_dir = \"../data/redd_processed/\"\n",
    "# for h_idx in train_house_list:\n",
    "#     for cur_app in appliance_list:\n",
    "#         cur_out_dir = os.path.join(out_base_dir, \"original\", \"normalized\", cur_app, \"train\")\n",
    "        \n",
    "#         if not os.path.exists(cur_out_dir):\n",
    "#             os.makedirs(cur_out_dir)\n",
    "        \n",
    "#         cur_path = os.path.join(cur_out_dir, \"h\" + str(h_idx) + \"_p{}.csv\")\n",
    "#         splitSegments_Store(df_normalized[h_idx].copy(), cur_path=cur_path, appliance=cur_app)\n",
    "#         print(\"\\n\")\n",
    "#     print(\"\\n\")\n",
    "\n",
    "\n",
    "# for h_idx in test_house_list:\n",
    "#     for cur_app in appliance_list:\n",
    "#         cur_out_dir = os.path.join(out_base_dir, \"original\", \"normalized\", cur_app, \"test\")\n",
    "        \n",
    "#         if not os.path.exists(cur_out_dir):\n",
    "#             os.makedirs(cur_out_dir)\n",
    "        \n",
    "#         cur_path = os.path.join(cur_out_dir, \"h\" + str(h_idx) + \"_p{}.csv\")\n",
    "#         splitSegments_Store(df_normalized[h_idx].copy(), cur_path=cur_path, appliance=cur_app)\n",
    "#         print(\"\\n\")\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store the raw data:\n",
    "\n",
    "# train_house_list = [1, 2, 3, 4]\n",
    "# test_house_list = [5, 6]\n",
    "# appliance_list = [\"refrigerator\", \"dishwaser\"]\n",
    "\n",
    "# out_base_dir = \"../data/redd_processed/\"\n",
    "# for h_idx in train_house_list:\n",
    "#     for cur_app in appliance_list:\n",
    "#         cur_out_dir = os.path.join(out_base_dir, \"original\", \"raw\", cur_app, \"train\")\n",
    "        \n",
    "#         if not os.path.exists(cur_out_dir):\n",
    "#             os.makedirs(cur_out_dir)\n",
    "        \n",
    "#         cur_path = os.path.join(cur_out_dir, \"h\" + str(h_idx) + \"_p{}.csv\")\n",
    "#         splitSegments_Store(df[h_idx].copy(), cur_path=cur_path, appliance=cur_app)\n",
    "#         print(\"\\n\")\n",
    "#     print(\"\\n\")\n",
    "\n",
    "\n",
    "# for h_idx in test_house_list:\n",
    "#     for cur_app in appliance_list:\n",
    "#         cur_out_dir = os.path.join(out_base_dir, \"original\", \"raw\", cur_app, \"test\")\n",
    "        \n",
    "#         if not os.path.exists(cur_out_dir):\n",
    "#             os.makedirs(cur_out_dir)\n",
    "        \n",
    "#         cur_path = os.path.join(cur_out_dir, \"h\" + str(h_idx) + \"_p{}.csv\")\n",
    "#         splitSegments_Store(df[h_idx].copy(), cur_path=cur_path, appliance=cur_app)\n",
    "#         print(\"\\n\")\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-saying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-morrison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "protecting-calculation",
   "metadata": {},
   "source": [
    "## Train/test split:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-cruise",
   "metadata": {},
   "source": [
    "### 1. Create windows of data points with a given window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "maritime-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSamples(cur_df, cur_window_segment=33, target_col=\"dishwaser\", causal=False):\n",
    "    cur_df_cols = list(cur_df.columns)\n",
    "    cur_df_timestamps = cur_df[\"time_stamp\"]\n",
    "    cur_df = cur_df.round(4)\n",
    "    cur_df_list = cur_df.to_numpy()\n",
    "    input_cols=[\"mains_1\", \"mains_2\"]\n",
    "    \n",
    "    # Find the col idx\n",
    "    input_col_idx = []\n",
    "    target_col_idx = None\n",
    "    for idx, cur_col in enumerate(cur_df_cols):\n",
    "        if target_col in cur_col:\n",
    "            target_col_idx = idx\n",
    "            break\n",
    "     \n",
    "    for inp_col in input_cols:\n",
    "        input_col_idx.append(cur_df_cols.index(inp_col))\n",
    "            \n",
    "    # Create the data samples\n",
    "    x_cols = [\"time_stamp\"]\n",
    "    for inp_col in input_cols:\n",
    "        prev_list = []\n",
    "        for i in range(cur_window_segment-1):\n",
    "            prev_list.append(inp_col + \"_prev_\" + str(i+1))\n",
    "        prev_list = list(reversed(prev_list))\n",
    "\n",
    "        next_list = []\n",
    "        if not causal:\n",
    "            for i in range(cur_window_segment-1):\n",
    "                next_list.append(inp_col + \"_next_\" + str(i+1))\n",
    "            \n",
    "        x_cols += prev_list + [inp_col] + next_list\n",
    "    \n",
    "    y_cols = [\"output\"]\n",
    "    cols = x_cols + y_cols\n",
    "    data = []\n",
    "        \n",
    "    num_records = len(cur_df_list)\n",
    "    for idx in range(num_records):\n",
    "        cur_start = idx - cur_window_segment + 1\n",
    "        \n",
    "        if causal:\n",
    "            cur_end = idx + 1\n",
    "        else:\n",
    "            cur_end = idx + cur_window_segment\n",
    "        \n",
    "        if cur_start < 0 or cur_end > num_records:\n",
    "            continue\n",
    "            \n",
    "        cur_timestamp = [cur_df_timestamps[idx]]\n",
    "        cur_input = None\n",
    "        for inp_col_idx in input_col_idx:\n",
    "            if cur_input is None:\n",
    "                cur_input = list(cur_df_list[cur_start:cur_end, inp_col_idx])\n",
    "            else:\n",
    "                cur_input += list(cur_df_list[cur_start:cur_end, inp_col_idx])\n",
    "        \n",
    "        # Filter the samples containing all same values for mains_1 window and mains_2 window (so only 2 unique values):\n",
    "        if len(np.unique(cur_input)) <= 2:\n",
    "            continue\n",
    "        \n",
    "        cur_output = list(cur_df_list[idx, [target_col_idx]])\n",
    "        data.append(cur_timestamp + cur_input + cur_output)\n",
    "\n",
    "    df_out = pd.DataFrame(data=data, columns=cols)\n",
    "    return df_out\n",
    "\n",
    "def create_train_test_split(data_dir, out_dir, window_segment = 3, train_house_list = [1, 2, 3, 4], test_house_list = [5, 6]):\n",
    "    # Note: Window segment should be of the form 2^n + 1\n",
    "    appliance_list = [\"refrigerator\", \"dishwaser\"]\n",
    "    causal_type = False\n",
    "    \n",
    "    for cur_appliance in appliance_list:\n",
    "        # Create training data\n",
    "        df_train = None\n",
    "        \n",
    "        print(\"Appliance =\", cur_appliance)\n",
    "        for cur_house_idx in tqdm(train_house_list):\n",
    "            \n",
    "            try:\n",
    "                house_data_path = os.path.join(data_dir, \"house_{}_data.csv\".format(cur_house_idx))\n",
    "                cur_df = pd.read_csv(house_data_path)\n",
    "\n",
    "                if df_train is None:\n",
    "                    df_train = createSamples(cur_df.copy(), cur_window_segment=window_segment, target_col=cur_appliance, causal=causal_type)\n",
    "                    df_train[\"house_idx\"] = cur_house_idx\n",
    "                else:\n",
    "                    c_df = createSamples(cur_df.copy(), cur_window_segment=window_segment, target_col=cur_appliance, causal=causal_type)\n",
    "                    c_df[\"house_idx\"] = cur_house_idx\n",
    "                    df_train = df_train.append(c_df, ignore_index=True)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(\"Skipped House =\", cur_house_idx, \" for appliance =\", cur_appliance)\n",
    "                \n",
    "        # Write the output to folder\n",
    "        out_app_folder = os.path.join(out_dir, \"window_{}\".format(window_segment), cur_appliance)\n",
    "        \n",
    "        if not os.path.exists(out_app_folder):\n",
    "            os.makedirs(out_app_folder)\n",
    "        \n",
    "        out_train_path = os.path.join(out_app_folder, \"train.csv\")\n",
    "        print(\"Writing data to \", out_train_path)\n",
    "        df_train.set_index(\"time_stamp\", inplace=True)\n",
    "        df_train.to_csv(out_train_path)\n",
    "        \n",
    "        \n",
    "        # Create testing data\n",
    "        df_test = None\n",
    "        for cur_house_idx in tqdm(test_house_list):\n",
    "            \n",
    "            try:\n",
    "                house_data_path = os.path.join(data_dir, \"house_{}_data.csv\".format(cur_house_idx))\n",
    "                cur_df = pd.read_csv(house_data_path)\n",
    "\n",
    "                if df_test is None:\n",
    "                    df_test = createSamples(cur_df.copy(), cur_window_segment=window_segment, target_col=cur_appliance, causal=causal_type)\n",
    "                    df_test[\"house_idx\"] = cur_house_idx\n",
    "                else:\n",
    "                    c_df = createSamples(cur_df.copy(), cur_window_segment=window_segment, target_col=cur_appliance, causal=causal_type)\n",
    "                    c_df[\"house_idx\"] = cur_house_idx\n",
    "                    df_test = df_test.append(c_df, ignore_index=True)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(\"Skipped House =\", cur_house_idx, \" for appliance =\", cur_appliance)\n",
    "        \n",
    "        # Write the output to folder\n",
    "        out_test_path = os.path.join(out_app_folder, \"test.csv\")\n",
    "        print(\"Writing data to \", out_test_path)\n",
    "        df_test.set_index(\"time_stamp\", inplace=True)\n",
    "        df_test.to_csv(out_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "instrumental-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dir = \"../data/redd_processed/low_freq/\"\n",
    "out_dir = \"../data/redd_processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "create_train_test_split(inp_dir, out_dir, window_segment = 3, train_house_list = [1], test_house_list = [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-verification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-solid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "window_seg_list = [33, 65, 129, 257]\n",
    "for cur_seg in window_seg_list:\n",
    "    create_train_test_split(inp_dir, out_dir, window_segment = cur_seg, train_house_list = [1, 2, 3, 4], test_house_list = [5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-carry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-ending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-medicaid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
